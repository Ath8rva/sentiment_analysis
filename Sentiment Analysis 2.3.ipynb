

import pandas as pd
import googleapiclient.discovery
import google_auth_oauthlib.flow
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
from afinn import Afinn

api_service_name = "youtube"
api_version = "v3"
DEVELOPER_KEY = ''

youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey = DEVELOPER_KEY)

df = pd.read_csv('Videos.csv')
df = df.drop('Unnamed: 0', axis = 1)
print(df.iloc[:20, 1])

0      415302
1     1154712
2     3199901
3     3540074
4     7112675
5     2869393
6     7933007
7     1862952
8     3291161
9     4150655
10    2879801
11    2683872
12    2900788
13    5187368
14    3652847
15    2289309
16    2913553
17    4262004
18    8822631
19    2430988
Name: Views, dtype: int64

df[['Likes', 'DisLikes']] = df[['Likes', 'DisLikes']].apply(pd.to_numeric)
new = df.sort_values(['Likes'], ascending=False)
new.head()

	Video ID 	Views 	Likes 	DisLikes 	Comments
133 	o-_WXXVye3Y 	6259778 	633177 	24118 	49507
88 	QtMzV73NAgk 	13352813 	574867 	11729 	41157
285 	MevKTPN4ozw 	13596729 	507261 	7927 	27838
93 	Sx6dAx7dnXg 	12388176 	429070 	11194 	34752
75 	UdfSrJvqY_E 	11639541 	399205 	12316 	47062

def com_list(rsp):
    for i in rsp['items']:
        cl.append(i['snippet']['topLevelComment']['snippet']['textOriginal'])

cl = []
c = 0
for vid in new['Video ID']:
    request = youtube.commentThreads().list(part="snippet", maxResults=100, textFormat="plainText", videoId=vid)
    response = request.execute()
    com_list(response)
    try:
        nxt = response['nextPageToken']
        i = 0
        while nxt != None and i < 199:
            request = youtube.commentThreads().list(part="snippet", maxResults=100, pageToken=nxt, textFormat="plainText", videoId=vid)
            response = request.execute()
            nxt = response['nextPageToken']
            com_list(response)
            i += 1
    except:
        print('Error')
    c += 1
    if c == 5:
        break

Error
Error

stopwords = set(STOPWORDS)
stopwords.update(['video'])
wordcloud = WordCloud(width = 1920, height = 1080, stopwords = stopwords, 
                      background_color = "white", min_word_length = 4).generate(' '.join(cl))
wordcloud.to_file('Pos.png')
plt.figure(figsize=(120,60))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

corpus = ' '.join(cl)
afn = Afinn()

print('Total Sentiment:', afn.score(corpus))
dic = wordcloud.words_
for i in list(dic.keys()):
    if afn.score(i) != 0:
        print(i, afn.score(i))

Total Sentiment: 105897.0
love 3.0
good 3.0
great 3.0
want 1.0
better 2.0
Thank 2.0
racism -3.0
best 3.0
racist -3.0
nice 3.0
matter 1.0
care 2.0
hope 2.0
amazing 4.0
awesome 4.0
cool 1.0
shit -4.0
best tech 3.0
please 1.0
problem -2.0
support 2.0
dislike -2.0
respect 2.0
damn -2.0
wish 1.0
kind 2.0
hate -3.0
help 2.0
worth 2.0
sound quality 2.0
ugly -3.0
quality 2.0
stop -1.0
huge 1.0
friend 1.0
wrong -2.0

pos, neg, ntl = 0, 0, 0
for i in cl:
    if afn.score(i) > 0:
        pos += 1
    elif afn.score(i) < 0:
        neg += 1
    else:
        ntl += 1

print(pos, neg, ntl)

37283 15289 28325

pos, neg, ntl = 0, 0, 0
for i in list(dic.keys()):
    if afn.score(i) > 0:
        pos += 1
    elif afn.score(i) < 0:
        neg += 1
    else:
        ntl += 1

print(pos, neg, ntl)

26 10 164

df[['Likes', 'DisLikes']] = df[['Likes', 'DisLikes']].apply(pd.to_numeric)
new = df.sort_values(['DisLikes'], ascending=False)
new.head()

	Video ID 	Views 	Likes 	DisLikes 	Comments
130 	gfC8Y66tR6o 	2588608 	115632 	36535 	12785
261 	P5dxd-ocaE8 	7688514 	372992 	25193 	35668
133 	o-_WXXVye3Y 	6259778 	633177 	24118 	49507
239 	vtqtyyGZvXM 	16441413 	332872 	16223 	31089
105 	eAagtcAup0o 	3210183 	185163 	13835 	16168

cl = []
c = 0
for vid in new['Video ID']:
    request = youtube.commentThreads().list(part="snippet", maxResults=100, textFormat="plainText", videoId=vid)
    response = request.execute()
    com_list(response)
    try:
        nxt = response['nextPageToken']
        i = 0
        while nxt != None and i < 199:
            request = youtube.commentThreads().list(part="snippet", maxResults=100, pageToken=nxt, textFormat="plainText", videoId=vid)
            response = request.execute()
            nxt = response['nextPageToken']
            com_list(response)
            i += 1
    except:
        print('Error')
    c += 1
    if c == 5:
        break

Error
Error

wordcloud = WordCloud(width = 1920, height = 1080, stopwords = stopwords, 
                      background_color = "white", min_word_length = 4).generate(' '.join(cl))
wordcloud.to_file('Neg.png')
plt.figure(figsize=(120,60))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

corpus = ' '.join(cl)
afn = Afinn()

print('Total Sentiment:', afn.score(corpus))
dic = wordcloud.words_
for i in list(dic.keys()):
    if afn.score(i) != 0:
        print(i, afn.score(i))

Total Sentiment: 54187.0
good 3.0
love 3.0
want 1.0
Thank 2.0
problem -2.0
great 3.0
racism -3.0
better 2.0
dislike -2.0
best 3.0
racist -3.0
matter 1.0
shit -4.0
care 2.0
hope 2.0
nice 3.0
hate -3.0
best tech 3.0
cool 1.0
disliked -2.0
please 1.0
respect 2.0
amazing 4.0
kind 2.0
support 2.0
wrong -2.0
stop -1.0
quality 2.0
help 2.0
awesome 4.0
honest 2.0
sorry -1.0
stupid -2.0
damn -2.0
yeah 1.0
fuck -4.0

pos, neg, ntl = 0, 0, 0
for i in cl:
    if afn.score(i) > 0:
        pos += 1
    elif afn.score(i) < 0:
        neg += 1
    else:
        ntl += 1

print(pos, neg, ntl)

31463 21999 27936

pos, neg, ntl = 0, 0, 0
for i in list(dic.keys()):
    if afn.score(i) > 0:
        pos += 1
    elif afn.score(i) < 0:
        neg += 1
    else:
        ntl += 1

print(pos, neg, ntl)

23 13 164

 

